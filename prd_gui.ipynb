{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox, filedialog\n",
    "from sklearn.preprocessing import RobustScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "\n",
    "# Load data and preprocess\n",
    "def load_and_preprocess_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Drop the 'sample_id' column if it exists\n",
    "    if 'sample_id' in data.columns:\n",
    "        data.drop(columns=['sample_id'], inplace=True)\n",
    "\n",
    "    # Features and target\n",
    "    X = data[['curing_days', 'cement', 'flyash', 'water', 'sa', 'viscosity', 'max_airt', 'max_var']]\n",
    "    y = data[\"UCS\"]\n",
    "\n",
    "    # Apply log transformation to the target variable\n",
    "    y_log = np.log1p(y)\n",
    "\n",
    "    # Robust scaling\n",
    "    scaler = RobustScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Feature Engineering - Adding polynomial features\n",
    "    poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    X_scaled = np.concatenate([X_scaled, X_poly[:, len(X.columns):]], axis=1)\n",
    "\n",
    "    return X_scaled, y_log, scaler, poly\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial, X_scaled, y_log):\n",
    "    param = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 50),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 2000),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 50),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.1, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.1, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "    }\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_list = []\n",
    "\n",
    "    for train_index, valid_index in kf.split(X_scaled):\n",
    "        X_train, X_valid = X_scaled[train_index], X_scaled[valid_index]\n",
    "        y_train, y_valid = y_log[train_index], y_log[valid_index]\n",
    "\n",
    "        model = lgb.LGBMRegressor(**param, verbose=-1)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_valid)\n",
    "        rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "        rmse_list.append(rmse)\n",
    "\n",
    "    return np.mean(rmse_list)\n",
    "\n",
    "# Run Optuna optimization\n",
    "def optimize_model(X_scaled, y_log):\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(lambda trial: objective(trial, X_scaled, y_log), n_trials=100)\n",
    "    return study.best_params\n",
    "\n",
    "# Save model, scaler, and polynomial features\n",
    "def save_model_and_scaler(model, scaler, poly):\n",
    "    with open('lightgbm_model.pkl', 'wb') as model_file:\n",
    "        pickle.dump(model, model_file)\n",
    "    with open('scaler.pkl', 'wb') as scaler_file:\n",
    "        pickle.dump(scaler, scaler_file)\n",
    "    with open('poly.pkl', 'wb') as poly_file:\n",
    "        pickle.dump(poly, poly_file)\n",
    "\n",
    "# Save predictions and metrics to Excel\n",
    "def save_predictions_to_excel(y_valid, y_pred, metrics):\n",
    "    predictions_df = pd.DataFrame({\n",
    "        'Actual': y_valid,\n",
    "        'Predicted': y_pred\n",
    "    })\n",
    "\n",
    "    # Add metrics to the DataFrame\n",
    "    for key, value in metrics.items():\n",
    "        predictions_df[key] = value\n",
    "\n",
    "    # Save to Excel\n",
    "    output_file = 'predictions_and_metrics.xlsx'\n",
    "    predictions_df.to_excel(output_file, index=False)\n",
    "    messagebox.showinfo(\"Success\", f\"Predictions and metrics saved to {output_file}\")\n",
    "\n",
    "# GUI Application\n",
    "class ModelApp:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"UCS Prediction using LightGBM\")\n",
    "\n",
    "        # Developer information\n",
    "        self.dev_label = tk.Label(master, text=\"Developer: Arienkhe Endurance Osemudiamhen\")\n",
    "        self.dev_label.pack()\n",
    "        self.dev_id_label = tk.Label(master, text=\"Student_ID: FS22020004E\")\n",
    "        self.dev_id_label.pack()\n",
    "        self.dev_email_label = tk.Label(master, text=\"Email: endurance@cumt.edu.cn\")\n",
    "        self.dev_email_label.pack()\n",
    "\n",
    "        self.label = tk.Label(master, text=\"Load CSV Data:\")\n",
    "        self.label.pack()\n",
    "\n",
    "        self.load_data_button = tk.Button(master, text=\"Load Data\", command=self.load_data)\n",
    "        self.load_data_button.pack()\n",
    "\n",
    "        self.optimize_button = tk.Button(master, text=\"Optimize Model\", command=self.optimize_model, state=tk.DISABLED)\n",
    "        self.optimize_button.pack()\n",
    "\n",
    "        self.result_label = tk.Label(master, text=\"\")\n",
    "        self.result_label.pack()\n",
    "\n",
    "        self.data = None\n",
    "        self.scaler = None\n",
    "        self.poly = None\n",
    "        self.model = None\n",
    "\n",
    "    def load_data(self):\n",
    "        file_path = filedialog.askopenfilename(filetypes=[(\"CSV files\", \"*.csv\")])\n",
    "        if file_path:\n",
    "            self.data = load_and_preprocess_data(file_path)\n",
    "            self.result_label.config(text=\"Data loaded and preprocessed!\")\n",
    "            self.optimize_button.config(state=tk.NORMAL)\n",
    "\n",
    "    def optimize_model(self):\n",
    "        X_scaled, y_log, self.scaler, self.poly = self.data\n",
    "        best_params = optimize_model(X_scaled, y_log)\n",
    "\n",
    "        # Train the final model with the best parameters\n",
    "        self.model = lgb.LGBMRegressor(**best_params)\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        metrics_list = []\n",
    "        all_y_valid = []\n",
    "        all_y_pred = []\n",
    "        \n",
    "        for train_index, valid_index in kf.split(X_scaled):\n",
    "            X_train, X_valid = X_scaled[train_index], X_scaled[valid_index]\n",
    "            y_train, y_valid = y_log[train_index], y_log[valid_index]\n",
    "\n",
    "            self.model.fit(X_train, y_train)\n",
    "            y_pred = self.model.predict(X_valid)\n",
    "\n",
    "            # Collect actual and predicted values\n",
    "            all_y_valid.extend(np.expm1(y_valid))  # Reverse log transformation\n",
    "            all_y_pred.extend(np.expm1(y_pred))    # Reverse log transformation\n",
    "\n",
    "            # Calculate metrics\n",
    "            rmse = np.sqrt(mean_squared_error(np.expm1(y_valid), np.expm1(y_pred)))\n",
    "            r2 = r2_score(np.expm1(y_valid), np.expm1(y_pred))\n",
    "            mae = mean_absolute_error(np.expm1(y_valid), np.expm1(y_pred))\n",
    "\n",
    "            metrics = {\n",
    "                'RMSE': rmse,\n",
    "                'R²': r2,\n",
    "                'MAE': mae\n",
    "            }\n",
    "            metrics_list.append(metrics)\n",
    "\n",
    "        # Average metrics\n",
    "        avg_metrics = {\n",
    "            'RMSE': np.mean([m['RMSE'] for m in metrics_list]),\n",
    "            'R²': np.mean([m['R²'] for m in metrics_list]),\n",
    "            'MAE': np.mean([m['MAE'] for m in metrics_list])\n",
    "        }\n",
    "\n",
    "        # Save the final model and scaler\n",
    "        save_model_and_scaler(self.model, self.scaler, self.poly)\n",
    "        \n",
    "        # Save predictions and metrics to Excel\n",
    "        save_predictions_to_excel(all_y_valid, all_y_pred, avg_metrics)\n",
    "\n",
    "        self.result_label.config(text=\"Model optimized and results saved!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = ModelApp(root)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
